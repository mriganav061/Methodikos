a:186:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:24:"Data Tier Implementation";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:39;}i:4;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:39;}i:5;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:39;}i:6;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:136:" Related Technologies: Hadoop, Big Data, HBase, PostgreSQL, Spring Data Hadoop, Spring Integration, Spring Batch, MapReduce, Sqoop, HDFS";}i:2;i:43;}i:7;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:179;}i:8;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:179;}i:9;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:179;}i:10;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:179;}i:11;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:19:" Sample Architeture";}i:2;i:183;}i:12;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:202;}i:13;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:202;}i:14;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:202;}i:15;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:202;}i:16;a:3:{i:0;s:13:"internalmedia";i:1;a:7:{i:0;s:43:":wiki:dc64f7bbce2b9f78a3876195499a50cd.jpeg";i:1;N;i:2;N;i:3;N;i:4;N;i:5;s:5:"cache";i:6;s:7:"details";}i:2;i:203;}i:17;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:250;}i:18;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:251;}i:19;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:251;}i:20;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:8:"Subtasks";i:1;i:2;i:2;i:251;}i:2;i:251;}i:21;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:251;}i:22;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:251;}i:23;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Completed:";}i:2;i:272;}i:24;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:282;}i:25;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:282;}i:26;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:282;}i:27;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:282;}i:28;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:286;}i:29;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:14:":ec2-local-dns";i:1;s:34:"Local DNS/NTP Server Configuration";}i:2;i:287;}i:30;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:340;}i:31;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:340;}i:32;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:340;}i:33;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:340;}i:34;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:64:" Test Data will be used from Bryan district PMIS data .csv file.";}i:2;i:344;}i:35;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:408;}i:36;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:408;}i:37;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:408;}i:38;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:408;}i:39;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:412;}i:40;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:14:":ec2-zookeeper";i:1;s:19:"Configure ZooKeeper";}i:2;i:413;}i:41;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:451;}i:42;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:451;}i:43;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:451;}i:44;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:451;}i:45;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:455;}i:46;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:13:":ec2-postgres";i:1;s:39:"Configure PostgreSQL at EC2 master node";}i:2;i:456;}i:47;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:513;}i:48;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:513;}i:49;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:513;}i:50;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:513;}i:51;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:517;}i:52;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:18:":ec2-hadoop-config";i:1;s:62:"Configure Hadoop system at EC2 (e.g. use 1 master and 1 slave)";}i:2;i:518;}i:53;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:603;}i:54;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:603;}i:55;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:603;}i:56;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:603;}i:57;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:607;}i:58;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:17:":ec2-hbase-config";i:1;s:15:"Configure HBase";}i:2;i:608;}i:59;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:645;}i:60;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:645;}i:61;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:645;}i:62;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:645;}i:63;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:649;}i:64;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:28:"initial package requirements";i:1;s:18:"Define Key Columns";}i:2;i:650;}i:65;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:701;}i:66;a:3:{i:0;s:6:"smiley";i:1;a:1:{i:0;s:3:":!:";}i:2;i:702;}i:67;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:705;}i:68;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:705;}i:69;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:705;}i:70;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:705;}i:71;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:709;}i:72;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:20:":ec2-important-ports";i:1;s:15:"Important Ports";}i:2;i:710;}i:73;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:750;}i:74;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:750;}i:75;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:750;}i:76;a:3:{i:0;s:2:"hr";i:1;a:0:{}i:2;i:751;}i:77;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:751;}i:78;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:5:"Todo:";}i:2;i:757;}i:79;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:762;}i:80;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:762;}i:81;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:762;}i:82;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:762;}i:83;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:766;}i:84;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:23:":methodikos-db-modeling";i:1;s:17:"Database Modeling";}i:2;i:767;}i:85;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:812;}i:86;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:812;}i:87;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:2;}i:2;i:812;}i:88;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:812;}i:89;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:23:" Consists of designing ";}i:2;i:818;}i:90;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:27:":methodikos-domain-modeling";i:1;s:12:"domain model";}i:2;i:841;}i:91;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:36:" and how effectively we can perform ";}i:2;i:885;}i:92;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:30:":methodikos-business-operation";i:1;s:19:"business operations";}i:2;i:921;}i:93;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:88:" (e.g. segmentation or IBC Analysis) on multiple nodes with MapReduce programming model.";}i:2;i:975;}i:94;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1063;}i:95;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1063;}i:96;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:2;}i:2;i:1063;}i:97;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1063;}i:98;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:80:" Important concepts: MapReduce on Hadoop with HBase support, Domain Model Design";}i:2;i:1069;}i:99;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1149;}i:100;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1149;}i:101;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:1149;}i:102;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1149;}i:103;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1149;}i:104;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1149;}i:105;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:64:" Below steps will be done after having firm client side ui logic";}i:2;i:1153;}i:106;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1217;}i:107;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:1217;}i:108;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:2;}i:2;i:1217;}i:109;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1217;}i:110;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:34:" Importing .csv file to PostgreSQL";}i:2;i:1223;}i:111;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1257;}i:112;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1257;}i:113;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:2;}i:2;i:1257;}i:114;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1257;}i:115;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:54:" Using Sqoop, import PostgreSQL data to HBase at HDFS.";}i:2;i:1263;}i:116;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1317;}i:117;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1317;}i:118;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:2;}i:2;i:1317;}i:119;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1317;}i:120;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:39:" Configure Spring Framework Data Hadoop";}i:2;i:1323;}i:121;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1362;}i:122;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1362;}i:123;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:2;}i:2;i:1362;}i:124;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1362;}i:125;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:26:" Doing some MapReduce work";}i:2;i:1368;}i:126;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1394;}i:127;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1394;}i:128;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:1394;}i:129;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1394;}i:130;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1394;}i:131;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1394;}i:132;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1398;}i:133;a:3:{i:0;s:12:"deleted_open";i:1;a:0:{}i:2;i:1399;}i:134;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:50:"Design prototype user interface for data importing";}i:2;i:1404;}i:135;a:3:{i:0;s:13:"deleted_close";i:1;a:0:{}i:2;i:1454;}i:136;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1460;}i:137;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1460;}i:138;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1460;}i:139;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1460;}i:140;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:" Wiring user interface";}i:2;i:1464;}i:141;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1486;}i:142;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1486;}i:143;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:1486;}i:144;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1487;}i:145;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:15:"Troubleshooting";i:1;i:2;i:2;i:1487;}i:2;i:1487;}i:146;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:1487;}i:147;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:1514;}i:148;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1514;}i:149;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1514;}i:150;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:96:" Not able to remotely connect from local machine to ec2 hbase both from shell and from java code";}i:2;i:1518;}i:151;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1614;}i:152;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1614;}i:153;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:1614;}i:154;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:1615;}i:155;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1615;}i:156;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1615;}i:157;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:436:" Hmaster registers its address with ZK. And from there client will come to know where to look for Hmaster. And if the Hmaster registers its address as 'localhost', the client will take it as the 'localhost', which is client's 'localhost' and not the 'localhost' where Hmaster is running. So, if you have the IP and hostname of the Hmaster in your /etc/hosts file the client can reach that machine without any problem as there is proper ";}i:2;i:1619;}i:158;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"DNS";}i:2;i:2055;}i:159;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:" resolution available.";}i:2;i:2058;}i:160;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2080;}i:161;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2080;}i:162;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:2080;}i:163;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:2081;}i:164;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2081;}i:165;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2081;}i:166;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:406:" When it comes to ec2 instances, Hmaster registers its internal domain name (e.g. domU-12-31-39-06-90-9E.compute-1.internal) to zookeeper. So when we try to connect to HBase cluster residing at AWS from outside of AWS, the remote machine has to know the public ip of domU-12-31-39-06-90-9E.compute-1.internal. This is handled by /etc/hosts in the remote machine. Add something like followings to /etc/hosts";}i:2;i:2085;}i:167;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2491;}i:168;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2491;}i:169;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:2491;}i:170;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:2491;}i:171;a:3:{i:0;s:6:"plugin";i:1;a:4:{i:0;s:9:"code_code";i:1;a:4:{i:0;s:4:"code";i:1;N;i:2;s:0:"";i:3;s:100:"
23.20.133.182 domU-12-31-39-06-90-9E.compute-1.internal
50.17.12.105 ip-10-164-71-62.ec2.internal 
";}i:2;i:3;i:3;s:101:">
23.20.133.182 domU-12-31-39-06-90-9E.compute-1.internal
50.17.12.105 ip-10-164-71-62.ec2.internal 
";}i:2;i:2497;}i:172;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:0:"";}i:2;i:2605;}i:173;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:2606;}i:174;a:3:{i:0;s:10:"listu_open";i:1;a:0:{}i:2;i:2606;}i:175;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:2606;}i:176;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:2606;}i:177;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:59:" Version compatibility issue with spring data hadoop, hbase";}i:2;i:2610;}i:178;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:2669;}i:179;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:2669;}i:180;a:3:{i:0;s:11:"listu_close";i:1;a:0:{}i:2;i:2669;}i:181;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2670;}i:182;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:23:"Data Tier Configuration";i:1;i:2;i:2;i:2670;}i:2;i:2670;}i:183;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:2670;}i:184;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:2705;}i:185;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:2705;}}